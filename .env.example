# Example configuration for GhostWriter
# Point to the Little Red Riding Hood testbed by default
GW_BOOK_BASE_DIR=testdata/LittleRedRidingHood

# Optional fine-grained overrides (resolve relative to GW_BOOK_BASE_DIR if not absolute)
# GW_SETTING_PATH=SETTING.yaml
# GW_CHARACTERS_PATH=CHARACTERS.yaml
# GW_CHAPTERS_DIR=chapters
# GW_ITERATIONS_DIR=iterations

# LLM configuration (optional; offline/mock mode when key is missing)
# OPENAI_API_KEY=sk-...
# LLM model and token limits
# Preferred default model key; the driver falls back to legacy OPENAI_MODEL if unset.
GW_MODEL_DEFAULT=gpt-4o-mini
# Legacy (still recognized as fallback):
# OPENAI_MODEL=gpt-4o-mini
# Token parameter name (some providers require 'max_completion_tokens')
GW_TOKENS_PARAM=max_tokens
# If your provider expects the total token limit (prompt + completion), enable this:
# 1 = include an estimated prompt token count in the limit; 0 = limit applies to completion only
GW_INCLUDE_PROMPT_TOKENS=0
# Approximate characters per token used for prompt token estimation (default 4)
GW_CHARS_PER_TOKEN=4
# Optional extra padding tokens added on top of the estimate
GW_PROMPT_TOKENS_PAD=0
# Optional hard cap to avoid overly large computed limits
GW_MAX_TOKENS_CAP=64000
# If the model returns empty output, retry once after adding this many tokens to the limit
GW_RETRY_TOKEN_INCREMENT=0
# Crash tracing (breadcrumbs + faulthandler)
GW_CRASH_TRACE=1

############################################
# Global defaults and per-step overrides   #
############################################

# Global defaults (used when per-step values are not set)
GW_TEMP_DEFAULT=0.2
GW_MAX_TOKENS_DEFAULT=800

# Per-step output length controls (tokens)
# If unset or invalid, GW_MAX_TOKENS_DEFAULT is used.
GW_MAX_TOKENS_CHECK=1600
GW_MAX_TOKENS_SUGGESTIONS=800
GW_MAX_TOKENS_STORY_SO_FAR=1200
GW_MAX_TOKENS_STORY_RELATIVE=1400
GW_MAX_TOKENS_BRAIN_STORM=600
GW_MAX_TOKENS_ORDERING=600
GW_MAX_TOKENS_GENERATE_NARRATION=1000
GW_MAX_TOKENS_ACTOR_ASSIGNMENT=600
GW_MAX_TOKENS_BODY_LANGUAGE=300
GW_MAX_TOKENS_AGENDA=300
GW_MAX_TOKENS_REACTIONS=400
GW_MAX_TOKENS_SUBTLE_EDIT=1000
GW_MAX_TOKENS_POLISH_PROSE=2000
# Dialog step (character-level)
GW_MAX_TOKENS_CHARACTER_DIALOG=120

# Dialog context lines default when not specified per call/template
GW_DIALOG_CONTEXT_LINES=8

# Iteration behavior
GW_SKIP_SUMMARIES=0
# Disable ordering step in dialog pipelines (use brainstorm bullets directly)
GW_DISABLE_ORDERING_DIALOG=0
GW_DISABLE_ORDERING_IMPLICIT=0
############################################
# Optional per-step model overrides         #
############################################
# If unset, OPENAI_MODEL is used.
GW_MODEL_CHECK=
GW_MODEL_SUGGESTIONS=
GW_MODEL_STORY_SO_FAR=
GW_MODEL_STORY_RELATIVE=
GW_MODEL_BRAIN_STORM=
GW_MODEL_ORDERING=
GW_MODEL_GENERATE_NARRATION=
GW_MODEL_ACTOR_ASSIGNMENT=
GW_MODEL_BODY_LANGUAGE=
GW_MODEL_AGENDA=
GW_MODEL_REACTIONS=
GW_MODEL_SUBTLE_EDIT=
GW_MODEL_POLISH_PROSE=
# Dialog step (character-level)
GW_MODEL_CHARACTER_DIALOG=

############################################
# Optional per-step temperature overrides   #
############################################
# If unset, GW_TEMP_DEFAULT is used.
GW_TEMP_CHECK=0.0
GW_TEMP_SUGGESTIONS=0.0
GW_TEMP_STORY_SO_FAR=0.2
GW_TEMP_STORY_RELATIVE=0.2
GW_TEMP_BRAIN_STORM=0.4
GW_TEMP_ORDERING=0.2
GW_TEMP_GENERATE_NARRATION=0.35
GW_TEMP_ACTOR_ASSIGNMENT=0.25
GW_TEMP_BODY_LANGUAGE=0.3
GW_TEMP_AGENDA=0.3
GW_TEMP_REACTIONS=0.3
GW_TEMP_SUBTLE_EDIT=0.2
GW_TEMP_POLISH_PROSE=0.2
# Dialog step (character-level). Dialog prioritizes character/template hints first.
GW_TEMP_CHARACTER_DIALOG=0.3

# Some providers only support default temperature (1). If you get an
# 'Unsupported value: temperature' error, set GW_TEMP_DEFAULT=1 or the
# specific GW_TEMP_* to 1. The driver also auto-fallbacks by retrying
# without temperature and then with temperature=1.
# Provider credentials and endpoints
OPENAI_API_KEY=
# OPENAI_BASE_URL=
# OPENAI_API_BASE=
# Azure OpenAI (optional)
# AZURE_OPENAI_API_KEY=
# AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_API_VERSION=2024-02-01
#
# Note: This project targets OpenAI and Azure OpenAI only. No OpenRouter support.

# Iteration behavior
GW_MAX_ITERATIONS=2
GW_SKIP_SUMMARIES=0
