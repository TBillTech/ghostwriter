# Example configuration for GhostWriter
# Point to the Little Red Riding Hood testbed by default
GW_BOOK_BASE_DIR=testdata/LittleRedRidingHood

# Optional fine-grained overrides (resolve relative to GW_BOOK_BASE_DIR if not absolute)
# GW_SETTING_PATH=SETTING.yaml
# GW_CHARACTERS_PATH=CHARACTERS.yaml
# GW_CHAPTERS_DIR=chapters
# GW_ITERATIONS_DIR=iterations

# LLM configuration (optional; offline/mock mode when key is missing)
# OPENAI_API_KEY=sk-...

# Preferred default model key; the driver falls back to legacy OPENAI_MODEL if unset.
GW_MODEL_DEFAULT=gpt-4o-mini
# Legacy (still recognized as fallback):
# OPENAI_MODEL=gpt-4o-mini

# Token budgeting
# Some providers expect 'max_completion_tokens' (recommended); others use 'max_tokens'.
# When set to 'max_completion_tokens', the limit applies to completion only.
GW_TOKENS_PARAM=max_completion_tokens
# If set to 1, include an estimated prompt token count in the limit (only applies when using 'max_tokens').
# Ignored when GW_TOKENS_PARAM=max_completion_tokens.
GW_INCLUDE_PROMPT_TOKENS=0
# Approximate characters per token used for prompt token estimation (default 4)
GW_CHARS_PER_TOKEN=4
# Optional extra padding tokens added on top of the estimate
GW_PROMPT_TOKENS_PAD=0
# Optional hard cap to avoid overly large computed completion limits
GW_MAX_COMPLETION_TOKENS_CAP=128000
# Reserve some tokens to avoid hitting hard model limits (applies to completion budgeting)
GW_COMPLETION_BUFFER=2000
# Ensure at least this many completion tokens are requested (post-cap/buffer)
GW_MIN_COMPLETION_TOKENS=200
# If the model returns empty output, retry once after adding this many tokens to the limit
GW_RETRY_TOKEN_INCREMENT=0

# Crash tracing (breadcrumbs + faulthandler)
GW_CRASH_TRACE=1

############################################
# Global defaults and per-step overrides   #
############################################

# Global defaults (used when per-step values are not set)
GW_TEMP_DEFAULT=0.2
GW_MAX_TOKENS_DEFAULT=800

# Per-step output length controls (tokens)
# If unset or invalid, GW_MAX_TOKENS_DEFAULT is used.
GW_MAX_TOKENS_CHECK=1600
GW_MAX_TOKENS_SUGGESTIONS=800
GW_MAX_TOKENS_STORY_SO_FAR=1200
GW_MAX_TOKENS_STORY_RELATIVE=1400
GW_MAX_TOKENS_BRAIN_STORM=600
GW_MAX_TOKENS_ORDERING=600
GW_MAX_TOKENS_GENERATE_NARRATION=1000
GW_MAX_TOKENS_ACTOR_ASSIGNMENT=600
GW_MAX_TOKENS_BODY_LANGUAGE=300
GW_MAX_TOKENS_AGENDA=300
GW_MAX_TOKENS_REACTIONS=400
GW_MAX_TOKENS_SUBTLE_EDIT=1000
GW_MAX_TOKENS_POLISH_PROSE=2000
# Dialog step (character-level)
GW_MAX_TOKENS_CHARACTER_DIALOG=120

# Dialog context lines default when not specified per call/template
GW_DIALOG_CONTEXT_LINES=8

# Iteration behavior
GW_SKIP_SUMMARIES=0
# Disable ordering step in dialog pipelines (use brainstorm bullets directly)
GW_DISABLE_ORDERING_DIALOG=0
GW_DISABLE_ORDERING_IMPLICIT=0

############################################
# Reasoning effort controls                 #
############################################
# Allowed values: low | medium | high
# Global default if nothing else is set
GW_REASONING_EFFORT=low
# Optional separate default, used if set (overrides GW_REASONING_EFFORT)
# GW_REASONING_EFFORT_DEFAULT=low
# Per-step overrides (examples):
# GW_REASONING_EFFORT_BRAIN_STORM=medium
# GW_REASONING_EFFORT_ORDERING=low
# GW_REASONING_EFFORT_GENERATE_NARRATION=medium
# Per-prompt overrides (highest precedence). The KEY is derived from the prompt filename
# by uppercasing the base name and removing a trailing "_prompt". Examples:
#   prompts/narration_brain_storm_prompt.md -> NARRATION_BRAIN_STORM
#   prompts/dialog_brain_storm_prompt.md    -> DIALOG_BRAIN_STORM
#   prompts/implicit_brain_storm_prompt.md  -> IMPLICIT_BRAIN_STORM
#   prompts/brainstorm_content_table_next.md-> BRAINSTORM_CONTENT_TABLE_NEXT
# Examples:
# GW_REASONING_EFFORT_PROMPT_IMPLICIT_BRAIN_STORM=high
# GW_REASONING_EFFORT_PROMPT_NARRATION_BRAIN_STORM=medium
# GW_REASONING_EFFORT_PROMPT_BRAINSTORM_CONTENT_TABLE_NEXT=medium
# GW_REASONING_EFFORT_PROMPT_CHARACTER_DIALOG=high

############################################
# Optional per-step model overrides         #
############################################
# If unset, OPENAI_MODEL is used.
GW_MODEL_CHECK=
GW_MODEL_SUGGESTIONS=
GW_MODEL_STORY_SO_FAR=
GW_MODEL_STORY_RELATIVE=
GW_MODEL_BRAIN_STORM=
GW_MODEL_ORDERING=
GW_MODEL_GENERATE_NARRATION=
GW_MODEL_ACTOR_ASSIGNMENT=
GW_MODEL_BODY_LANGUAGE=
GW_MODEL_AGENDA=
GW_MODEL_REACTIONS=
GW_MODEL_SUBTLE_EDIT=
GW_MODEL_POLISH_PROSE=
# Dialog step (character-level)
GW_MODEL_CHARACTER_DIALOG=

############################################
# Per-prompt overrides (model/temp/tokens)  #
############################################
# Highest precedence. Use KEY as described above in the Reasoning section.
# Examples:
# GW_MODEL_PROMPT_IMPLICIT_BRAIN_STORM=gpt-5-mini
# GW_TEMP_PROMPT_IMPLICIT_BRAIN_STORM=0.5
# GW_MAX_TOKENS_PROMPT_IMPLICIT_BRAIN_STORM=12000

############################################
# Optional per-step temperature overrides   #
############################################
# If unset, GW_TEMP_DEFAULT is used.
GW_TEMP_CHECK=0.0
GW_TEMP_SUGGESTIONS=0.0
GW_TEMP_STORY_SO_FAR=0.2
GW_TEMP_STORY_RELATIVE=0.2
GW_TEMP_BRAIN_STORM=0.4
GW_TEMP_ORDERING=0.2
GW_TEMP_GENERATE_NARRATION=0.35
GW_TEMP_ACTOR_ASSIGNMENT=0.25
GW_TEMP_BODY_LANGUAGE=0.3
GW_TEMP_AGENDA=0.3
GW_TEMP_REACTIONS=0.3
GW_TEMP_SUBTLE_EDIT=0.2
GW_TEMP_POLISH_PROSE=0.2
# Dialog step (character-level). Dialog prioritizes character/template hints first.
GW_TEMP_CHARACTER_DIALOG=0.3
# Force env temperature for character dialog (override character/template hints)
# Set to 1 to always use GW_TEMP_CHARACTER_DIALOG even if characters/templates suggest a different temperature.
GW_FORCE_TEMP_CHARACTER_DIALOG=0

# Some providers only support default temperature (1). If you get an
# 'Unsupported value: temperature' error, set GW_TEMP_DEFAULT=1 or the
# specific GW_TEMP_* to 1. The driver also auto-fallbacks by retrying
# without temperature and then with temperature=1.

# Provider credentials and endpoints
OPENAI_API_KEY=
# OPENAI_BASE_URL=
# OPENAI_API_BASE=
# Azure OpenAI (optional)
# AZURE_OPENAI_API_KEY=
# AZURE_OPENAI_ENDPOINT=
# AZURE_OPENAI_API_VERSION=2024-02-01
#
# Note: This project targets OpenAI and Azure OpenAI only. No OpenRouter support.

# Iteration behavior
GW_MAX_ITERATIONS=2
GW_SKIP_SUMMARIES=0
